{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1jliNtm0FNKFWJ0CGPins",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkro/pytorch_for_deep_learning/blob/main/01_pytorch_workflow_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch Workflow\n",
        "\n",
        "Explore a pytorch end-to-end workflow.\n",
        "\n",
        "Resources:\n",
        "\n",
        "https://github.com/mrdbourke/pytorch-deep-learning/blob/main/01_pytorch_workflow.ipynb\n",
        "\n",
        "https://www.learnpytorch.io/01_pytorch_workflow/\n",
        "\n",
        "https://github.com/mrdbourke/pytorch-deep-learning/discussions\n"
      ],
      "metadata": {
        "id": "XEMT9kmTXCnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "what_were_covering = {\n",
        "    1: \"data (prepare and load)\",\n",
        "    2: \"build model\",\n",
        "    3: \"fitting the model to the data (training)\",\n",
        "    4: \"making predictions (=inference)and evaluating a model\",\n",
        "    5: \"saving and loading a model\",\n",
        "    6: \"putting it all together\"\n",
        "}\n",
        "\n",
        "what_were_covering"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bt5M68QpX0DR",
        "outputId": "1aab8a26-6246-407e-e1c5-592883fd0f54"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'data (prepare and load)',\n",
              " 2: 'build model',\n",
              " 3: 'fitting the model to the data (training)',\n",
              " 4: 'making predictions (=inference)and evaluating a model',\n",
              " 5: 'saving and loading a model',\n",
              " 6: 'putting it all together'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.nn is for pytorch what keras is for tensorflow (more or less).\n",
        "\n",
        "GPT:\n",
        "\n",
        ">torch.nn provides a wide range of pre-defined layers, activation functions, loss functions, and other building blocks commonly used in deep learning. These components allow you to easily define the architecture of your neural network and specify how the data flows through the network.\n",
        ">\n",
        ">Similarly, Keras is a high-level neural networks API that provides a simplified and user-friendly interface for building and training neural networks. It also offers a wide range of pre-defined layers, activation functions, and loss functions, among other features. Keras is often praised for its ease of use and its ability to quickly prototype and experiment with different network architectures.\n",
        "\n",
        "https://pytorch.org/docs/stable/nn.html"
      ],
      "metadata": {
        "id": "QjXUmk-PZJlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn # nn contains all of PyTorch's building blocks for neural networks / graphs\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "zJw6L3oeYZI3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data (preparing and loading)\n",
        "\n",
        "Data can be almost anything in machine learning.\n",
        "\n",
        "- Excel spreadsheet\n",
        "- Images\n",
        "- Videos\n",
        "- Audio\n",
        "- DNA\n",
        "- Text\n",
        "\n",
        "Machine learning is a game of two parts:\n",
        "\n",
        "1. Get data into a numerical representation\n",
        "2. Build a model to learn patterns in that numerical representation\n",
        "\n",
        "Let's create some *known* data using the linear [regression formula](https://www.google.com/search?q=linear+regression+formula)\n",
        "\n",
        "![linear regression formula](https://drive.google.com/uc?id=1ScI7WdGHNNJB9lvrAFO50QHXcDABMjSl)\n",
        "\n",
        "[how to embed google drive images](https://medium.com/analytics-vidhya/embedding-your-image-in-google-colab-markdown-3998d5ac2684)\n",
        "\n",
        "Linear regression is a statistical modeling technique used to establish a relationship between a dependent variable and one or more independent variables. It assumes a linear relationship between the independent variables and the dependent variable. The general formula for linear regression can be expressed as follows:\n",
        "\n",
        "y = β0 + β1 * x1 + β2 * x2 + ... + βn * xn + ε\n",
        "\n",
        "In this formula:\n",
        "\n",
        "- y is the dependent variable (the variable we want to predict or explain).\n",
        "- x1, x2, ..., xn are the independent variables (also known as features or predictors).\n",
        "- β0, β1, β2, ..., βn are the coefficients (parameters) that represent the slope or weight of each independent variable. β0 is the intercept term.\n",
        "- ε represents the error term, which accounts for the variability in the dependent variable that is not explained by the independent variables.\n",
        "\n",
        "Let's create some *known* data using the linear [regression formula](https://www.google.com/search?q=linear+regression+formula).\n",
        "\n",
        "We'll use a linear regression formula to make a straight line with *known* parameters."
      ],
      "metadata": {
        "id": "ACdnwxC2Z0Uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create known parameters\n",
        "weight = 0.7 # \"b\" in the formula from the image\n",
        "bias = 0.3 # \"a\" in the formula from the image\n",
        "\n",
        "# Create\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1) # matrix or tensor, should be in capital; add extra dimension; explanation later\n",
        "# set labels according to the relationship we define. This is what the model should learn (even though we know it already as we defined it ourselves)\n",
        "# creates a tensor (formula is applied to each X)\n",
        "y = weight * X + bias\n",
        "\n",
        "X[:10], y[:10], len(X), len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFsmIz_wZVch",
        "outputId": "408be8db-fceb-4bca-827a-b42017f8f66c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0000],\n",
              "         [0.0200],\n",
              "         [0.0400],\n",
              "         [0.0600],\n",
              "         [0.0800],\n",
              "         [0.1000],\n",
              "         [0.1200],\n",
              "         [0.1400],\n",
              "         [0.1600],\n",
              "         [0.1800]]),\n",
              " tensor([[0.3000],\n",
              "         [0.3140],\n",
              "         [0.3280],\n",
              "         [0.3420],\n",
              "         [0.3560],\n",
              "         [0.3700],\n",
              "         [0.3840],\n",
              "         [0.3980],\n",
              "         [0.4120],\n",
              "         [0.4260]]),\n",
              " 50,\n",
              " 50)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### splitting data into training and test sets\n",
        "\n",
        "One of the most important concepts in machine learning.\n",
        "\n",
        "Analogy:\n",
        "\n",
        "Course materials = training set (model learns patterns)\n",
        "Practice exam = validation set (model tunes on this data)\n",
        "Final exam = test set (data the model hasn't seen before)\n",
        "\n",
        "Exception: language models.\n",
        "\n",
        "GPT:\n",
        "\n",
        "> the traditional concept of splitting data into separate training and test sets may not directly apply to language models in the same way as it does to supervised learning tasks with labeled data.\n",
        ">\n",
        ">In the context of language models, the primary goal is to train the model to generate coherent and contextually appropriate text based on the patterns and structures it learns from a given dataset. The evaluation of a language model is typically based on the quality and fluency of the generated text rather than a comparison with specific \"correct outcomes\" or ground truth labels.\n",
        ">\n",
        ">However, that doesn't mean that language models don't benefit from some form of evaluation or testing. Here are a few common approaches:\n",
        ">\n",
        ">- **Perplexity**: Perplexity is a metric commonly used to evaluate language models. It quantifies how well a language model predicts a given sequence of words. Lower perplexity values indicate better performance. You can compute perplexity on a held-out validation set or a separate portion of the dataset that was not used for training. This helps gauge the model's generalization ability and its ability to capture the underlying patterns in the language.\n",
        ">- **Human Evaluation**: Another approach is to conduct human evaluations where human judges assess the quality of the generated text. This can involve subjective assessments such as fluency, coherence, and relevance to a given prompt. Human evaluations can provide valuable insights into the performance and shortcomings of the language model.\n",
        ">- **Prompt Completion Evaluation**: In some cases, language models are evaluated based on their ability to complete given prompts or generate text in response to specific input. This can involve providing incomplete sentences or partial text and assessing how well the model generates the rest of the text.\n",
        ">\n",
        ">While traditional train-test splits may not be the primary approach for evaluating language models, the concept of having separate data for evaluation is still important. It allows you to assess the model's performance on unseen or held-out data and helps in understanding how well the model generalizes to different text inputs.\n",
        "\n"
      ],
      "metadata": {
        "id": "JH5t97sMhIvE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ac7MsEC8iDhn"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}